{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0603_roads_label01_v1",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa105Rcj6iDy"
      },
      "source": [
        "# 도로 검출\n",
        "\n",
        "## 파라미터 : \n",
        "*  epoch : 30\n",
        "* beta1: 0.9, beta2 : 0.999 \n",
        "* learning rate : 0.0001\n",
        "\n",
        "## 라벨링 방식 : 흑백 채우기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdmkWGKEwEC9",
        "outputId": "ceb83b53-8309-4056-e7e8-7d21548eee5c"
      },
      "source": [
        "!pip install segmentation_models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models\n",
            "  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hCollecting image-classifiers==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.16.2)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.5.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.2)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJLJFYTKzf_3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJRJI_oUuJvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e93b9b-e3dd-451d-9100-34a82a3f1203"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQZ02khSvKeY"
      },
      "source": [
        "import math\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import re\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZTvBXMh2VNB"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zSQc2MKuwQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab03e48c-52a9-465f-e012-5badb1f8ad2f"
      },
      "source": [
        "%env SM_FRAMEWORK=tf.keras\n",
        "\n",
        "import segmentation_models as sm"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: SM_FRAMEWORK=tf.keras\n",
            "Segmentation Models: using `tf.keras` framework.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxUVBql6ul6x",
        "outputId": "423fc7e6-a3ce-4b45-b7d6-73b7e159f366"
      },
      "source": [
        "!ls\n",
        "!ls /content/drive/MyDrive/SIA/colab_code/lhk"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n",
            "0603_bnr_label01_v1\t      0603_roads_label01_v1\n",
            "0603_bnr_label01_v1.h5\t      0603_roads_label01_v1.h5\n",
            "0603_buildings_label01_v1     binary_buildings_label01_v1.h5\n",
            "0603_buildings_label01_v1.h5  bnr_label01_v1.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4sl1Ffh1bOk"
      },
      "source": [
        "BACKBONE = 'efficientnetb3'\n",
        "BATCH_SIZE = 1\n",
        "LR = 0.0001\n",
        "EPOCHS = 30\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFZY0eBS1bzc"
      },
      "source": [
        "빌딩이냐 도로만 바꾸면됨 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4qp9j5ru95C"
      },
      "source": [
        "train_input_DIR =  '/content/drive/MyDrive/SIA/roads/train/raw_image/' #input 경로\n",
        "\n",
        "train_label_DIR = '/content/drive/MyDrive/SIA/roads/train/new_label/' #label 경로 \n",
        "\n",
        "val_input_DIR =  '/content/drive/MyDrive/SIA/roads/val/raw_image/' #input 경로\n",
        "\n",
        "val_label_DIR = '/content/drive/MyDrive/SIA/roads/val/new_label/' #label 경로 "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvpc1x4klL_q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paibqFPU0pxU"
      },
      "source": [
        "train_input = glob.glob(train_input_DIR  + '*.png')\n",
        "train_label  = glob.glob(train_label_DIR + '*.png')\n",
        "\n",
        "val_input = glob.glob(val_input_DIR  + '*.png')\n",
        "val_label  = glob.glob(val_label_DIR + '*.png')\n",
        "\n",
        "\n",
        "train_input.sort()\n",
        "train_label.sort()\n",
        "val_input.sort()\n",
        "val_label.sort()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz0KpqcO6L6x"
      },
      "source": [
        "CLASSES = ['roads']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mope9XPZuwQC"
      },
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "    \n",
        "# helper function for data visualization    \n",
        "def denormalize(x):\n",
        "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
        "    x_max = np.percentile(x, 98)\n",
        "    x_min = np.percentile(x, 2)    \n",
        "    x = (x - x_min) / (x_max - x_min)\n",
        "    x = x.clip(0, 1)\n",
        "    return x\n",
        "    \n",
        "\n",
        "# classes for data loading and preprocessing\n",
        "class Dataset_bi:\n",
        "    CLASSES =  ['roads','buildings']\n",
        "    \n",
        "    def __init__(\n",
        "            self, \n",
        "            images_dir, \n",
        "            masks_dir, \n",
        "            classes=None, \n",
        "            augmentation=None, \n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        self.ids = [i.split('/')[-1] for i in images_dir]\n",
        "        self.images_fps = images_dir\n",
        "        self.masks_fps = masks_dir\n",
        "        \n",
        "        # convert str names to class values on masks\n",
        "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
        "        \n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        image = cv2.imread(self.images_fps[i])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.masks_fps[i], 0)\n",
        "        mask = mask.reshape(1024,1024,-1)\n",
        "\n",
        "        \n",
        "        # add background if mask is not binary\n",
        "        if mask.shape[-1] != 1:\n",
        "            # 둘다 1일 경우..\n",
        "            background = 255 - mask.sum(axis=-1, keepdims=True)\n",
        "            mask = np.concatenate((mask, background), axis=-1)\n",
        "            mask = np.where(mask == 255, mask, 0)\n",
        "        \n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        \n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "            \n",
        "#         image = image/255         \n",
        "        mask = mask/255\n",
        "        return image, mask\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4lhncQwuwQF"
      },
      "source": [
        "class Dataloder(keras.utils.Sequence):\n",
        "    \"\"\"Load data from dataset and form batches\n",
        "    \n",
        "    Args:\n",
        "        dataset: instance of Dataset class for image loading and preprocessing.\n",
        "        batch_size: Integet number of images in batch.\n",
        "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(dataset))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # collect batch data\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "        \n",
        "        # transpose list of lists\n",
        "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
        "       \n",
        "        return tuple(batch)\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
        "        return len(self.indexes) // self.batch_size\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
        "        if self.shuffle:\n",
        "            self.indexes = np.random.permutation(self.indexes)   "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITm3C5lluwQG"
      },
      "source": [
        "import albumentations as A"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YZyJk2HuwQG"
      },
      "source": [
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        A.PadIfNeeded(1024, 1024)\n",
        "    ]\n",
        "    return A.Compose(test_transform)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ1HUXrWuwQH"
      },
      "source": [
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    \n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function \n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "    ]\n",
        "    return A.Compose(_transform)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT3QPvOTuwQI"
      },
      "source": [
        "train_dataset = Dataset_bi(\n",
        "    train_input,train_label \n",
        "    ,\n",
        "    classes=CLASSES,\n",
        "#         preprocessing=get_preprocessing(preprocess_input),\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU1gzeN2uwQK"
      },
      "source": [
        "valid_dataset = Dataset_bi(\n",
        "    val_input, val_label,\n",
        "    classes=CLASSES,    \n",
        "#     augmentation=get_validation_augmentation(),\n",
        "#         preprocessing=get_preprocessing(preprocess_input)\n",
        "\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djLHpAMmuwQK"
      },
      "source": [
        "\n",
        "## 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXDWlHo5uwQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05ae4d3-3fb4-4026-e6ce-6f79d64a9f83"
      },
      "source": [
        "# define network parameters\n",
        "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\n",
        "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
        "\n",
        "#create model\n",
        "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "44113920/44107200 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8MzHY0OyvXO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDVgNPMsuwQL"
      },
      "source": [
        "# define optomizer\n",
        "optim = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam'\n",
        ")\n",
        "\n",
        "\n",
        "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
        "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
        "dice_loss = sm.losses.DiceLoss() \n",
        "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
        "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
        "\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
        "\n",
        "# compile keras model with defined optimozer, loss and metrics\n",
        "model.compile(optim, total_loss, metrics)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzRFQjZAuwQL"
      },
      "source": [
        "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = Dataloder(valid_dataset, batch_size=1, shuffle=False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiJjNLN6uwQL"
      },
      "source": [
        "# assert train_dataloader[0][0].shape == (BATCH_SIZE, 1024, 1024, 3)\n",
        "# assert train_dataloader[0][1].shape == (BATCH_SIZE, 1024, 1024, n_classes)\n",
        "\n",
        "# define callbacks for learning rate scheduling and best checkpoints saving\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/SIA/colab_code/lhk/0603_roads_label01_v1.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
        "    keras.callbacks.ReduceLROnPlateau(),\n",
        "]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER7ytco2uwQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54e2cfc-25cf-4679-dff6-db38fecc5da2"
      },
      "source": [
        "model.summary"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <tensorflow.python.keras.engine.functional.Functional object at 0x7f23635c9c90>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfPDpNrguwQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a17ba561-8c92-4b7a-d229-0bf4bf10e461"
      },
      "source": [
        "# train model\n",
        "history = model.fit_generator(\n",
        "    train_dataloader, \n",
        "    steps_per_epoch=len(train_dataloader), \n",
        "    epochs=30, \n",
        "     callbacks=callbacks,      validation_data=valid_dataloader, \n",
        "    validation_steps=len(valid_dataloader) ,verbose = 1 \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            " 244/1144 [=====>........................] - ETA: 17:45 - loss: 0.6275 - iou_score: 0.3776 - f1-score: 0.5225"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUUP8hLzuwQM"
      },
      "source": [
        "# Plot training & validation iou_score values\n",
        "plt.figure(figsize=(30, 8))\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['iou_score'])\n",
        "plt.plot(history.history['val_iou_score'])\n",
        "plt.title('Model iou_score')\n",
        "plt.ylabel('iou_score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irrSiMRiy-wi"
      },
      "source": [
        "## 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX0arTz-uwQM"
      },
      "source": [
        "test_dataset = Dataset_bi(\n",
        "    val_input, val_label,\n",
        "    classes=CLASSES,    \n",
        "#     augmentation=get_validation_augmentation(),\n",
        "#         preprocessing=get_preprocessing(preprocess_input)\n",
        "\n",
        ")\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPWfv8oYuwQM"
      },
      "source": [
        "\n",
        "# load best weights\n",
        "model.load_weights('/content/drive/MyDrive/SIA/colab_code/lhk/0603_roads_label01_v1.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5bctPgCuwQN"
      },
      "source": [
        "scores = model.evaluate_generator(test_dataloader)\n",
        "\n",
        "print(\"Loss: {:.5}\".format(scores[0]))\n",
        "for metric, value in zip(metrics, scores[1:]):\n",
        "    print(\"mean {}: {:.5}\".format(metric.__name__, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cHUFtPruwQN"
      },
      "source": [
        "n = 5\n",
        "ids = np.random.choice(np.arange(len(test_dataset)), size=n)\n",
        "\n",
        "for i in ids:\n",
        "    \n",
        "    image, gt_mask = test_dataset[i]\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pr_mask = model.predict(image)\n",
        "    \n",
        "    visualize(\n",
        "        image=denormalize(image.squeeze()),\n",
        "        gt_mask=gt_mask.squeeze(),\n",
        "        pr_mask=pr_mask.squeeze(),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qtJ4_otuwQN"
      },
      "source": [
        "n = 5\n",
        "ids = np.random.choice(np.arange(len(test_dataset)), size=n)\n",
        "\n",
        "for i in ids:\n",
        "    \n",
        "    image, gt_mask = test_dataset[i]\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pr_mask = model.predict(image)\n",
        "    \n",
        "    visualize(\n",
        "        image=denormalize(image.squeeze()),\n",
        "        gt_mask=gt_mask.squeeze(),\n",
        "        pr_mask=pr_mask.squeeze(),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjB__Oxp2TXw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsqlNlyt3goL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}